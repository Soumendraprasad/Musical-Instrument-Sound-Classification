{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-12-29T15:40:45.904414Z","iopub.status.busy":"2022-12-29T15:40:45.903950Z","iopub.status.idle":"2022-12-29T15:40:46.916870Z","shell.execute_reply":"2022-12-29T15:40:46.915526Z","shell.execute_reply.started":"2022-12-29T15:40:45.904371Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Table of contents</center></h1> \n","1. [Introduction](#1)   \n","2. [Importing libraries](#2)\n","3. [Explore the csv file](#3)  \n","4. [Approach-1](#4)\n","5. [Approach-2](#5)\n","6. [Model](#6)     \n","7. [Model Test](#7)     \n","8.  [Thank You](#8)"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-12-29T07:50:07.246390Z","iopub.status.busy":"2022-12-29T07:50:07.245894Z","iopub.status.idle":"2022-12-29T07:50:07.257600Z","shell.execute_reply":"2022-12-29T07:50:07.255796Z","shell.execute_reply.started":"2022-12-29T07:50:07.246346Z"}},"source":["<a id=\"1\"></a> \n","\n","# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Introduction</center></h1> \n","\n","\n","    \n","Here we have  4 types of different classes of musical instruments  .\n","\n","- **GuitarSound - 700 Sounds in Train Set**\n","- **DrumSouund - 700 Sounds in Train Set**\n","- **ViolinSound - 700 Sound in Train Set**\n","- **PianoSound - 528 Sound in Train Set**\n","\n","In Test Set Total **80 audio files are present** , 20 From Each Class. Our work is to **classify them** according to their classes .\n","<font>\n","\n","<img src=\"https://www.scienceabc.com/wp-content/uploads/2019/08/Different-ethnic-music-instruments.-Save-culture.-Ethnic-world.-National-instruments.-ImageAnna_Kuzminas.jpg\" width=400 height=550/>"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"2\"></a> \n","\n","# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center> Importing Libraries</center></h1> "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:40:46.920195Z","iopub.status.busy":"2022-12-29T15:40:46.919408Z","iopub.status.idle":"2022-12-29T15:40:46.931321Z","shell.execute_reply":"2022-12-29T15:40:46.929956Z","shell.execute_reply.started":"2022-12-29T15:40:46.920138Z"},"trusted":true},"outputs":[],"source":["import os\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from scipy.io import wavfile\n","import librosa\n","import librosa.display\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense,Dropout,Activation\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"3\"></a> \n","\n","# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Exploring csv Files</center></h1> "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:40:46.933706Z","iopub.status.busy":"2022-12-29T15:40:46.933201Z","iopub.status.idle":"2022-12-29T15:40:46.950285Z","shell.execute_reply":"2022-12-29T15:40:46.949197Z","shell.execute_reply.started":"2022-12-29T15:40:46.933659Z"},"trusted":true},"outputs":[],"source":["\n","\n","df=pd.read_csv(\"/kaggle/input/musical-instruments-sound-dataset/Metadata_Train.csv\")\n","df2=pd.read_csv(\"/kaggle/input/musical-instruments-sound-dataset/Metadata_Test.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:40:46.952966Z","iopub.status.busy":"2022-12-29T15:40:46.952632Z","iopub.status.idle":"2022-12-29T15:40:46.965166Z","shell.execute_reply":"2022-12-29T15:40:46.964348Z","shell.execute_reply.started":"2022-12-29T15:40:46.952937Z"},"trusted":true},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:40:46.967122Z","iopub.status.busy":"2022-12-29T15:40:46.966765Z","iopub.status.idle":"2022-12-29T15:40:47.215728Z","shell.execute_reply":"2022-12-29T15:40:47.214495Z","shell.execute_reply.started":"2022-12-29T15:40:46.967089Z"},"trusted":true},"outputs":[],"source":["# Visualizing Tag column\n","\n","print(df['Class'].value_counts())\n","plt.figure(figsize=(22,10))\n","sns.countplot(df['Class'])\n","plt.xticks(rotation=0)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:40:47.217515Z","iopub.status.busy":"2022-12-29T15:40:47.216962Z","iopub.status.idle":"2022-12-29T15:40:47.467037Z","shell.execute_reply":"2022-12-29T15:40:47.465922Z","shell.execute_reply.started":"2022-12-29T15:40:47.217478Z"},"trusted":true},"outputs":[],"source":["print(df2['Class'].value_counts())\n","plt.figure(figsize=(22,10))\n","sns.countplot(df2['Class'])\n","plt.xticks(rotation=0)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"4\"></a> \n","# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Approach-1</center></h1> \n","\n","Here we will extract some features from each audio files & then we would remove the less information part of each audio"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:40:47.469169Z","iopub.status.busy":"2022-12-29T15:40:47.468563Z","iopub.status.idle":"2022-12-29T15:40:55.098618Z","shell.execute_reply":"2022-12-29T15:40:55.097416Z","shell.execute_reply.started":"2022-12-29T15:40:47.469134Z"},"trusted":true},"outputs":[],"source":["\n","df.set_index('FileName',inplace=True)\n","\n","for f in df.index:\n","    rate, signal = wavfile.read('/kaggle/input/musical-instruments-sound-dataset/Train_submission/Train_submission/' + f)\n","    df.at[f, 'length'] = signal.shape[0]/rate\n","\n","classes = list(np.unique(df.Class))\n","class_dist = df.groupby(['Class'])['length'].mean()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:40:55.100705Z","iopub.status.busy":"2022-12-29T15:40:55.100069Z","iopub.status.idle":"2022-12-29T15:40:55.204124Z","shell.execute_reply":"2022-12-29T15:40:55.202452Z","shell.execute_reply.started":"2022-12-29T15:40:55.100664Z"},"trusted":true},"outputs":[],"source":["# Volume of each labels\n","\n","fig, ax = plt.subplots()\n","ax.set_title('Class Distribution', y=1.08)\n","ax.pie(class_dist, labels=class_dist.index, autopct='%1.1f%%',\n","       shadow=False, startangle=90)\n","ax.axis('equal')\n","plt.show()\n","df.reset_index(inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["\n","# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Feature Extraction</center></h1> \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:40:55.207803Z","iopub.status.busy":"2022-12-29T15:40:55.206715Z","iopub.status.idle":"2022-12-29T15:40:55.218713Z","shell.execute_reply":"2022-12-29T15:40:55.216794Z","shell.execute_reply.started":"2022-12-29T15:40:55.207734Z"},"trusted":true},"outputs":[],"source":["# Calculate FFT\n","\n","def calc_fft(y,sr):\n","    \n","    n=len(y)\n","    freq=np.fft.rfftfreq(n,d=1/sr)\n","    Y=abs(np.fft.rfft(y)/n)\n","    return (Y,freq)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:40:55.230171Z","iopub.status.busy":"2022-12-29T15:40:55.228538Z","iopub.status.idle":"2022-12-29T15:40:55.243820Z","shell.execute_reply":"2022-12-29T15:40:55.241891Z","shell.execute_reply.started":"2022-12-29T15:40:55.230093Z"},"trusted":true},"outputs":[],"source":["# Valuable Info In Sample\n","\n","def Envelope(y, rate, threshold):\n","    mask = []\n","    #we want a rolling window so we create series as it is easy with it\n","    y = pd.Series(y).apply(np.abs)\n","    y_mean = y.rolling(window=int(rate/4), min_periods=1, center=True).mean()\n","    for mean in y_mean:\n","        if mean > threshold:\n","            mask.append(True)\n","        else:\n","            mask.append(False)\n","            \n","    return mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:40:55.248704Z","iopub.status.busy":"2022-12-29T15:40:55.246864Z","iopub.status.idle":"2022-12-29T15:40:58.841649Z","shell.execute_reply":"2022-12-29T15:40:58.840412Z","shell.execute_reply.started":"2022-12-29T15:40:55.248624Z"},"trusted":true},"outputs":[],"source":["# Taking One Audio from each class \n","# Applying some FE methods\n","\n","signals = {}\n","fft = {}\n","fnames=[]\n","mfccs = {}\n","\n","\n","for c in classes:\n","    wav_file = df[df.Class == c].iloc[0,0]\n","    fnames.append('/kaggle/input/musical-instruments-sound-dataset/Train_submission/Train_submission/'+wav_file)\n","    signal, rate = librosa.load('/kaggle/input/musical-instruments-sound-dataset/Train_submission/Train_submission/'+wav_file,sr=44100)\n","    mask = Envelope(signal, rate, 0.0005) #0.0005 is experimental\n","    signal = signal[mask]\n","    signals[c] = signal\n","    fft[c] = calc_fft(signal, rate)\n","    \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:40:58.843719Z","iopub.status.busy":"2022-12-29T15:40:58.843313Z","iopub.status.idle":"2022-12-29T15:40:59.487512Z","shell.execute_reply":"2022-12-29T15:40:59.486305Z","shell.execute_reply.started":"2022-12-29T15:40:58.843681Z"},"trusted":true},"outputs":[],"source":["# Plotting Signals\n","\n","def plot_signals(signals):\n","    fig, axes = plt.subplots(nrows=1, ncols=4, sharex=False,\n","                             sharey=True, figsize=(20,5))\n","    fig.suptitle('Time Series', size=16)\n","    i = 0\n","    for x in range(4):\n","            axes[x].set_title(list(signals.keys())[i])\n","            axes[x].plot(list(signals.values())[i])\n","            axes[x].get_xaxis().set_visible(False)\n","            axes[x].get_yaxis().set_visible(False)\n","            i += 1\n","plot_signals(signals)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:40:59.490161Z","iopub.status.busy":"2022-12-29T15:40:59.489404Z","iopub.status.idle":"2022-12-29T15:40:59.920611Z","shell.execute_reply":"2022-12-29T15:40:59.919773Z","shell.execute_reply.started":"2022-12-29T15:40:59.490113Z"},"trusted":true},"outputs":[],"source":["# Plotting ffts\n","\n","def plot_fft(fft):\n","    fig, axes = plt.subplots(nrows=1, ncols=4, sharex=False,\n","                             sharey=True, figsize=(20,5))\n","    fig.suptitle('Fourier Transforms', size=16)\n","    i = 0\n","    for x in range(4):\n","        \n","            data = list(fft.values())[i]\n","            Y, freq = data[0], data[1]\n","            axes[x].set_title(list(fft.keys())[i])\n","            axes[x].plot(freq, Y)\n","            axes[x].get_xaxis().set_visible(False)\n","            axes[x].get_yaxis().set_visible(False)\n","            i += 1\n","plot_fft(fft)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:40:59.923087Z","iopub.status.busy":"2022-12-29T15:40:59.922302Z","iopub.status.idle":"2022-12-29T15:41:02.070609Z","shell.execute_reply":"2022-12-29T15:41:02.069410Z","shell.execute_reply.started":"2022-12-29T15:40:59.923039Z"},"trusted":true},"outputs":[],"source":["# Mel Spectograms\n","\n","data=[]\n","hop_length = 512 \n","ename=list(signals.keys())\n","for i in fnames:\n","    y_data,sr_data=librosa.load(fnames[0])\n","    data.append(y_data)\n","\n","        \n","c1 = librosa.feature.melspectrogram(data[0], sr=25000)\n","S_c1 = librosa.amplitude_to_db(c1, ref=np.max)\n","\n","c2 = librosa.feature.melspectrogram(data[1], sr=25000)\n","S_c2 = librosa.amplitude_to_db(c2, ref=np.max)\n","\n","c3 = librosa.feature.melspectrogram(data[2], sr=25000)\n","S_c3 = librosa.amplitude_to_db(c3, ref=np.max)\n","\n","c4 = librosa.feature.melspectrogram(data[3], sr=25000)\n","S_c4 = librosa.amplitude_to_db(c4, ref=np.max)\n","\n","\n","\n","# === PLOT ====\n","fig, ax = plt.subplots(1, 4, figsize=(16, 9))\n","fig.suptitle('Mel Spectrogram', fontsize=16)\n","\n","\n","librosa.display.specshow(S_c1, sr =25000, hop_length = hop_length, x_axis = 'time', \n","                         y_axis = 'log', cmap = 'rainbow', ax=ax[0])\n","librosa.display.specshow(S_c2, sr=25000, hop_length = hop_length, x_axis = 'time', \n","                         y_axis = 'log', cmap = 'rainbow', ax=ax[1])\n","librosa.display.specshow(S_c3, sr=25000, hop_length = hop_length, x_axis = 'time', \n","                         y_axis = 'log', cmap = 'rainbow', ax=ax[2])\n","librosa.display.specshow(S_c4, sr=25000, hop_length = hop_length, x_axis = 'time', \n","                         y_axis = 'log', cmap = 'rainbow', ax=ax[3])\n","\n","\n","for i, name in zip(range(0, 1*4), ename):\n","    x = i % 4\n","    ax[x].set_title(name, fontsize=13)"]},{"cell_type":"markdown","metadata":{},"source":["**<span style=\"color:#3b3a30;\">Now the audios are down sampled . We could run this Envelope func to each file & then our data is ready for model creation . But I will show here another approach & we will create our model based on that approach . </span>**"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"5\"></a> \n","# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Approach-2</center></h1> \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:41:02.073151Z","iopub.status.busy":"2022-12-29T15:41:02.072284Z","iopub.status.idle":"2022-12-29T15:41:02.080300Z","shell.execute_reply":"2022-12-29T15:41:02.078924Z","shell.execute_reply.started":"2022-12-29T15:41:02.073105Z"},"trusted":true},"outputs":[],"source":["# mfcc Extractor\n","\n","def Feature_extractor(file):\n","    \n","    audio,sample_rate=librosa.load(file_name,res_type='kaiser_fast')\n","    mfccs_features=librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\n","    mfccs_scaled_features =np.mean(mfccs_features.T,axis=0)\n","    return mfccs_scaled_features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T15:42:58.695986Z","iopub.status.busy":"2022-12-29T15:42:58.695457Z","iopub.status.idle":"2022-12-29T15:42:58.702614Z","shell.execute_reply":"2022-12-29T15:42:58.701035Z","shell.execute_reply.started":"2022-12-29T15:42:58.695947Z"},"trusted":true},"outputs":[],"source":["extracted_features=[]\n","\n","for index_num,row in tqdm(df.iterrows()):\n","    file_name = os.path.join(os.path.abspath('/kaggle/input/musical-instruments-sound-dataset/Train_submission/Train_submission/'),str(row[\"FileName\"]))\n","    final_class_label=row[\"Class\"]\n","    data=Feature_extractor(file_name)\n","    extracted_features.append([data,final_class_label])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.567390Z","iopub.status.idle":"2022-12-29T15:42:47.568544Z","shell.execute_reply":"2022-12-29T15:42:47.568193Z","shell.execute_reply.started":"2022-12-29T15:42:47.568158Z"},"trusted":true},"outputs":[],"source":["extracted_features_df=pd.DataFrame(extracted_features,columns=['features','class'])\n","extracted_features_df.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.570112Z","iopub.status.idle":"2022-12-29T15:42:47.570542Z","shell.execute_reply":"2022-12-29T15:42:47.570362Z","shell.execute_reply.started":"2022-12-29T15:42:47.570328Z"},"trusted":true},"outputs":[],"source":["# from sklearn.preprocessing import LabelEncoder\n","X=np.array(extracted_features_df['features'].tolist())\n","y=np.array(extracted_features_df[\"class\"].tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.572475Z","iopub.status.idle":"2022-12-29T15:42:47.573323Z","shell.execute_reply":"2022-12-29T15:42:47.573120Z","shell.execute_reply.started":"2022-12-29T15:42:47.573090Z"},"trusted":true},"outputs":[],"source":["X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.574905Z","iopub.status.idle":"2022-12-29T15:42:47.575730Z","shell.execute_reply":"2022-12-29T15:42:47.575522Z","shell.execute_reply.started":"2022-12-29T15:42:47.575491Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","LE=LabelEncoder()\n","y=to_categorical(LE.fit_transform(y))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.577477Z","iopub.status.idle":"2022-12-29T15:42:47.577905Z","shell.execute_reply":"2022-12-29T15:42:47.577724Z","shell.execute_reply.started":"2022-12-29T15:42:47.577704Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.579531Z","iopub.status.idle":"2022-12-29T15:42:47.579943Z","shell.execute_reply":"2022-12-29T15:42:47.579768Z","shell.execute_reply.started":"2022-12-29T15:42:47.579749Z"},"trusted":true},"outputs":[],"source":["print(\"Shape Of X_train:\",X_train.shape)\n","print(\"Shape Of X_test:\",X_test.shape)\n","print(\"Shape Of y_train:\",y_train.shape)\n","print(\"Shape Of y_test:\",y_test.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.581229Z","iopub.status.idle":"2022-12-29T15:42:47.581680Z","shell.execute_reply":"2022-12-29T15:42:47.581497Z","shell.execute_reply.started":"2022-12-29T15:42:47.581478Z"},"trusted":true},"outputs":[],"source":["# Setting labels\n","num_labels=y.shape[1]"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"6\"></a> \n","# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Model</center></h1> "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.583750Z","iopub.status.idle":"2022-12-29T15:42:47.584657Z","shell.execute_reply":"2022-12-29T15:42:47.584459Z","shell.execute_reply.started":"2022-12-29T15:42:47.584436Z"},"trusted":true},"outputs":[],"source":["# Creating Our Model\n","\n","model=Sequential()\n","model.add(Dense(100,input_shape=(40,)))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.3))\n","\n","model.add(Dense(200))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.3))\n","\n","model.add(Dense(200))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.3))\n","\n","model.add(Dense(100))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.3))\n","\n","model.add(Dense(num_labels))\n","model.add(Activation('softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.585934Z","iopub.status.idle":"2022-12-29T15:42:47.587024Z","shell.execute_reply":"2022-12-29T15:42:47.586834Z","shell.execute_reply.started":"2022-12-29T15:42:47.586811Z"},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.588064Z","iopub.status.idle":"2022-12-29T15:42:47.589133Z","shell.execute_reply":"2022-12-29T15:42:47.588939Z","shell.execute_reply.started":"2022-12-29T15:42:47.588918Z"},"trusted":true},"outputs":[],"source":["model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.590260Z","iopub.status.idle":"2022-12-29T15:42:47.591269Z","shell.execute_reply":"2022-12-29T15:42:47.591066Z","shell.execute_reply.started":"2022-12-29T15:42:47.591035Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","# tf.keras.callbacks.ModelCheckpoint\n","from datetime import datetime\n","\n","num_epochs=100\n","num_batch_size=32\n","\n","checkpointer=ModelCheckpoint(filepath='saved_models/audio_classification.hdf5',verbose=1,save_best_only=True)\n","start=datetime.now()\n","history = model.fit(X_train,y_train,batch_size=num_batch_size,epochs=num_epochs,validation_data=(X_test,y_test),callbacks=checkpointer)\n","\n","duration=datetime.now()-start\n","print(\"Training Completed in time: \",duration)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.592649Z","iopub.status.idle":"2022-12-29T15:42:47.593547Z","shell.execute_reply":"2022-12-29T15:42:47.593305Z","shell.execute_reply.started":"2022-12-29T15:42:47.593284Z"},"trusted":true},"outputs":[],"source":["def plot_accuracy_loss(history):\n","    \"\"\"\n","        Plot the accuracy and the loss during the training of the nn.\n","    \"\"\"\n","    fig = plt.figure(figsize=(10,5))\n","\n","    # Plot accuracy\n","    plt.subplot(221)\n","    plt.plot(history.history['accuracy'],'bo--', label = \"accuracy\")\n","    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_accuracy\")\n","    plt.title(\"train_accuracy vs val_accuracy\")\n","    plt.ylabel(\"accuracy\")\n","    plt.xlabel(\"epochs\")\n","    plt.legend()\n","\n","    # Plot loss function\n","    plt.subplot(222)\n","    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n","    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n","    plt.title(\"train_loss vs val_loss\")\n","    plt.ylabel(\"loss\")\n","    plt.xlabel(\"epochs\")\n","\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.595353Z","iopub.status.idle":"2022-12-29T15:42:47.595799Z","shell.execute_reply":"2022-12-29T15:42:47.595614Z","shell.execute_reply.started":"2022-12-29T15:42:47.595593Z"},"trusted":true},"outputs":[],"source":["plot_accuracy_loss(history)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n","print(test_accuracy[1])"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"7\"></a> \n","# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Testing our model</center></h1> "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.597251Z","iopub.status.idle":"2022-12-29T15:42:47.597711Z","shell.execute_reply":"2022-12-29T15:42:47.597527Z","shell.execute_reply.started":"2022-12-29T15:42:47.597507Z"},"trusted":true},"outputs":[],"source":["# Testing an audio from test set\n","\n","filename=\"/kaggle/input/musical-instruments-sound-dataset/Test_submission/Test_submission/Sad-Violin-Slow-K-www.fesliyanstudios.com.wav\"\n","audio,sample_rate=librosa.load(filename,res_type='kaiser_fast')\n","mfccs_features=librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\n","mfccs_scaled_features =np.mean(mfccs_features.T,axis=0)\n","\n","print(mfccs_scaled_features)\n","mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n","print(mfccs_scaled_features)\n","\n","predicted_label = np.argmax(model.predict(mfccs_scaled_features), axis=-1)\n","print(predicted_label)\n","\n","prediction_class=LE.inverse_transform(predicted_label)\n","prediction_class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.599188Z","iopub.status.idle":"2022-12-29T15:42:47.599625Z","shell.execute_reply":"2022-12-29T15:42:47.599437Z","shell.execute_reply.started":"2022-12-29T15:42:47.599417Z"},"trusted":true},"outputs":[],"source":["# Let's play that sound\n","\n","import IPython.display as ipd \n","ipd.Audio(filename)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a id=\"8\"></a> \n","# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Thank You</center></h1> \n"," \n","\n","### **You might like my another kernel[üê¶GUIDE TO:Audio Processing & FE With Birds Soundsüê¶](https://www.kaggle.com/code/soumendraprasad/guide-to-audio-processing-fe-with-birds-sounds/edit/run/114418780)** \n","\n","\n","<img src=\"https://media.tenor.com/0MqQbvj3peYAAAAC/thinking-for-watching.gif\" width= 700 height = 450 />\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
