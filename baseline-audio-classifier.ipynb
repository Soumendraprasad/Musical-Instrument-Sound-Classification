{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-12-29T15:40:45.903950Z","iopub.execute_input":"2022-12-29T15:40:45.904414Z","iopub.status.idle":"2022-12-29T15:40:46.916870Z","shell.execute_reply.started":"2022-12-29T15:40:45.904371Z","shell.execute_reply":"2022-12-29T15:40:46.915526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Table of contents</center></h1> \n1. [Introduction](#1)   \n2. [Importing libraries](#2)\n3. [Explore the csv file](#3)  \n4. [Approach-1](#4)\n5. [Approach-2](#5)\n6. [Model](#6)     \n7. [Model Test](#7)     \n8.  [Thank You](#8)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a> \n\n# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Introduction</center></h1> \n\n\n    \nHere we have  4 types of different classes of musical instruments  .\n\n- **GuitarSound - 700 Sounds in Train Set**\n- **DrumSouund - 700 Sounds in Train Set**\n- **ViolinSound - 700 Sound in Train Set**\n- **PianoSound - 528 Sound in Train Set**\n\nIn Test Set Total **80 audio files are present** , 20 From Each Class. Our work is to **classify them** according to their classes .\n<font>\n\n<img src=\"https://www.scienceabc.com/wp-content/uploads/2019/08/Different-ethnic-music-instruments.-Save-culture.-Ethnic-world.-National-instruments.-ImageAnna_Kuzminas.jpg\" width=400 height=550/>","metadata":{"execution":{"iopub.status.busy":"2022-12-29T07:50:07.245894Z","iopub.execute_input":"2022-12-29T07:50:07.246390Z","iopub.status.idle":"2022-12-29T07:50:07.257600Z","shell.execute_reply.started":"2022-12-29T07:50:07.246346Z","shell.execute_reply":"2022-12-29T07:50:07.255796Z"}}},{"cell_type":"markdown","source":"<a id=\"2\"></a> \n\n# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center> Importing Libraries</center></h1> ","metadata":{}},{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.io import wavfile\nimport librosa\nimport librosa.display\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout,Activation\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:40:46.919408Z","iopub.execute_input":"2022-12-29T15:40:46.920195Z","iopub.status.idle":"2022-12-29T15:40:46.931321Z","shell.execute_reply.started":"2022-12-29T15:40:46.920138Z","shell.execute_reply":"2022-12-29T15:40:46.929956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a> \n\n# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Exploring csv Files</center></h1> ","metadata":{}},{"cell_type":"code","source":"\n\ndf=pd.read_csv(\"/kaggle/input/musical-instruments-sound-dataset/Metadata_Train.csv\")\ndf2=pd.read_csv(\"/kaggle/input/musical-instruments-sound-dataset/Metadata_Test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:40:46.933201Z","iopub.execute_input":"2022-12-29T15:40:46.933706Z","iopub.status.idle":"2022-12-29T15:40:46.950285Z","shell.execute_reply.started":"2022-12-29T15:40:46.933659Z","shell.execute_reply":"2022-12-29T15:40:46.949197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:40:46.952632Z","iopub.execute_input":"2022-12-29T15:40:46.952966Z","iopub.status.idle":"2022-12-29T15:40:46.965166Z","shell.execute_reply.started":"2022-12-29T15:40:46.952937Z","shell.execute_reply":"2022-12-29T15:40:46.964348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing Tag column\n\nprint(df['Class'].value_counts())\nplt.figure(figsize=(22,10))\nsns.countplot(df['Class'])\nplt.xticks(rotation=0)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:40:46.966765Z","iopub.execute_input":"2022-12-29T15:40:46.967122Z","iopub.status.idle":"2022-12-29T15:40:47.215728Z","shell.execute_reply.started":"2022-12-29T15:40:46.967089Z","shell.execute_reply":"2022-12-29T15:40:47.214495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df2['Class'].value_counts())\nplt.figure(figsize=(22,10))\nsns.countplot(df2['Class'])\nplt.xticks(rotation=0)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:40:47.216962Z","iopub.execute_input":"2022-12-29T15:40:47.217515Z","iopub.status.idle":"2022-12-29T15:40:47.467037Z","shell.execute_reply.started":"2022-12-29T15:40:47.217478Z","shell.execute_reply":"2022-12-29T15:40:47.465922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4\"></a> \n# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Approach-1</center></h1> \n\nHere we will extract some features from each audio files & then we would remove the less information part of each audio","metadata":{}},{"cell_type":"code","source":"\ndf.set_index('FileName',inplace=True)\n\nfor f in df.index:\n    rate, signal = wavfile.read('/kaggle/input/musical-instruments-sound-dataset/Train_submission/Train_submission/' + f)\n    df.at[f, 'length'] = signal.shape[0]/rate\n\nclasses = list(np.unique(df.Class))\nclass_dist = df.groupby(['Class'])['length'].mean()\n","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:40:47.468563Z","iopub.execute_input":"2022-12-29T15:40:47.469169Z","iopub.status.idle":"2022-12-29T15:40:55.098618Z","shell.execute_reply.started":"2022-12-29T15:40:47.469134Z","shell.execute_reply":"2022-12-29T15:40:55.097416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Volume of each labels\n\nfig, ax = plt.subplots()\nax.set_title('Class Distribution', y=1.08)\nax.pie(class_dist, labels=class_dist.index, autopct='%1.1f%%',\n       shadow=False, startangle=90)\nax.axis('equal')\nplt.show()\ndf.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:40:55.100069Z","iopub.execute_input":"2022-12-29T15:40:55.100705Z","iopub.status.idle":"2022-12-29T15:40:55.204124Z","shell.execute_reply.started":"2022-12-29T15:40:55.100664Z","shell.execute_reply":"2022-12-29T15:40:55.202452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Feature Extraction</center></h1> \n","metadata":{}},{"cell_type":"code","source":"# Calculate FFT\n\ndef calc_fft(y,sr):\n    \n    n=len(y)\n    freq=np.fft.rfftfreq(n,d=1/sr)\n    Y=abs(np.fft.rfft(y)/n)\n    return (Y,freq)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:40:55.206715Z","iopub.execute_input":"2022-12-29T15:40:55.207803Z","iopub.status.idle":"2022-12-29T15:40:55.218713Z","shell.execute_reply.started":"2022-12-29T15:40:55.207734Z","shell.execute_reply":"2022-12-29T15:40:55.216794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Valuable Info In Sample\n\ndef Envelope(y, rate, threshold):\n    mask = []\n    #we want a rolling window so we create series as it is easy with it\n    y = pd.Series(y).apply(np.abs)\n    y_mean = y.rolling(window=int(rate/4), min_periods=1, center=True).mean()\n    for mean in y_mean:\n        if mean > threshold:\n            mask.append(True)\n        else:\n            mask.append(False)\n            \n    return mask","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:40:55.228538Z","iopub.execute_input":"2022-12-29T15:40:55.230171Z","iopub.status.idle":"2022-12-29T15:40:55.243820Z","shell.execute_reply.started":"2022-12-29T15:40:55.230093Z","shell.execute_reply":"2022-12-29T15:40:55.241891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Taking One Audio from each class \n# Applying some FE methods\n\nsignals = {}\nfft = {}\nfnames=[]\nmfccs = {}\n\n\nfor c in classes:\n    wav_file = df[df.Class == c].iloc[0,0]\n    fnames.append('/kaggle/input/musical-instruments-sound-dataset/Train_submission/Train_submission/'+wav_file)\n    signal, rate = librosa.load('/kaggle/input/musical-instruments-sound-dataset/Train_submission/Train_submission/'+wav_file,sr=44100)\n    mask = Envelope(signal, rate, 0.0005) #0.0005 is experimental\n    signal = signal[mask]\n    signals[c] = signal\n    fft[c] = calc_fft(signal, rate)\n    \n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:40:55.246864Z","iopub.execute_input":"2022-12-29T15:40:55.248704Z","iopub.status.idle":"2022-12-29T15:40:58.841649Z","shell.execute_reply.started":"2022-12-29T15:40:55.248624Z","shell.execute_reply":"2022-12-29T15:40:58.840412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting Signals\n\ndef plot_signals(signals):\n    fig, axes = plt.subplots(nrows=1, ncols=4, sharex=False,\n                             sharey=True, figsize=(20,5))\n    fig.suptitle('Time Series', size=16)\n    i = 0\n    for x in range(4):\n            axes[x].set_title(list(signals.keys())[i])\n            axes[x].plot(list(signals.values())[i])\n            axes[x].get_xaxis().set_visible(False)\n            axes[x].get_yaxis().set_visible(False)\n            i += 1\nplot_signals(signals)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:40:58.843313Z","iopub.execute_input":"2022-12-29T15:40:58.843719Z","iopub.status.idle":"2022-12-29T15:40:59.487512Z","shell.execute_reply.started":"2022-12-29T15:40:58.843681Z","shell.execute_reply":"2022-12-29T15:40:59.486305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting ffts\n\ndef plot_fft(fft):\n    fig, axes = plt.subplots(nrows=1, ncols=4, sharex=False,\n                             sharey=True, figsize=(20,5))\n    fig.suptitle('Fourier Transforms', size=16)\n    i = 0\n    for x in range(4):\n        \n            data = list(fft.values())[i]\n            Y, freq = data[0], data[1]\n            axes[x].set_title(list(fft.keys())[i])\n            axes[x].plot(freq, Y)\n            axes[x].get_xaxis().set_visible(False)\n            axes[x].get_yaxis().set_visible(False)\n            i += 1\nplot_fft(fft)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:40:59.489404Z","iopub.execute_input":"2022-12-29T15:40:59.490161Z","iopub.status.idle":"2022-12-29T15:40:59.920611Z","shell.execute_reply.started":"2022-12-29T15:40:59.490113Z","shell.execute_reply":"2022-12-29T15:40:59.919773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mel Spectograms\n\ndata=[]\nhop_length = 512 \nename=list(signals.keys())\nfor i in fnames:\n    y_data,sr_data=librosa.load(fnames[0])\n    data.append(y_data)\n\n        \nc1 = librosa.feature.melspectrogram(data[0], sr=25000)\nS_c1 = librosa.amplitude_to_db(c1, ref=np.max)\n\nc2 = librosa.feature.melspectrogram(data[1], sr=25000)\nS_c2 = librosa.amplitude_to_db(c2, ref=np.max)\n\nc3 = librosa.feature.melspectrogram(data[2], sr=25000)\nS_c3 = librosa.amplitude_to_db(c3, ref=np.max)\n\nc4 = librosa.feature.melspectrogram(data[3], sr=25000)\nS_c4 = librosa.amplitude_to_db(c4, ref=np.max)\n\n\n\n# === PLOT ====\nfig, ax = plt.subplots(1, 4, figsize=(16, 9))\nfig.suptitle('Mel Spectrogram', fontsize=16)\n\n\nlibrosa.display.specshow(S_c1, sr =25000, hop_length = hop_length, x_axis = 'time', \n                         y_axis = 'log', cmap = 'rainbow', ax=ax[0])\nlibrosa.display.specshow(S_c2, sr=25000, hop_length = hop_length, x_axis = 'time', \n                         y_axis = 'log', cmap = 'rainbow', ax=ax[1])\nlibrosa.display.specshow(S_c3, sr=25000, hop_length = hop_length, x_axis = 'time', \n                         y_axis = 'log', cmap = 'rainbow', ax=ax[2])\nlibrosa.display.specshow(S_c4, sr=25000, hop_length = hop_length, x_axis = 'time', \n                         y_axis = 'log', cmap = 'rainbow', ax=ax[3])\n\n\nfor i, name in zip(range(0, 1*4), ename):\n    x = i % 4\n    ax[x].set_title(name, fontsize=13)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:40:59.922302Z","iopub.execute_input":"2022-12-29T15:40:59.923087Z","iopub.status.idle":"2022-12-29T15:41:02.070609Z","shell.execute_reply.started":"2022-12-29T15:40:59.923039Z","shell.execute_reply":"2022-12-29T15:41:02.069410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**<span style=\"color:#3b3a30;\">Now the audios are down sampled . We could run this Envelope func to each file & then our data is ready for model creation . But I will show here another approach & we will create our model based on that approach . </span>**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"5\"></a> \n# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Approach-2</center></h1> \n","metadata":{}},{"cell_type":"code","source":"# mfcc Extractor\n\ndef Feature_extractor(file):\n    \n    audio,sample_rate=librosa.load(file_name,res_type='kaiser_fast')\n    mfccs_features=librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\n    mfccs_scaled_features =np.mean(mfccs_features.T,axis=0)\n    return mfccs_scaled_features","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:41:02.072284Z","iopub.execute_input":"2022-12-29T15:41:02.073151Z","iopub.status.idle":"2022-12-29T15:41:02.080300Z","shell.execute_reply.started":"2022-12-29T15:41:02.073105Z","shell.execute_reply":"2022-12-29T15:41:02.078924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extracted_features=[]\n\nfor index_num,row in tqdm(df.iterrows()):\n    file_name = os.path.join(os.path.abspath('/kaggle/input/musical-instruments-sound-dataset/Train_submission/Train_submission/'),str(row[\"FileName\"]))\n    final_class_label=row[\"Class\"]\n    data=Feature_extractor(file_name)\n    extracted_features.append([data,final_class_label])","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:58.695457Z","iopub.execute_input":"2022-12-29T15:42:58.695986Z","iopub.status.idle":"2022-12-29T15:42:58.702614Z","shell.execute_reply.started":"2022-12-29T15:42:58.695947Z","shell.execute_reply":"2022-12-29T15:42:58.701035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extracted_features_df=pd.DataFrame(extracted_features,columns=['features','class'])\nextracted_features_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.567390Z","iopub.status.idle":"2022-12-29T15:42:47.568544Z","shell.execute_reply.started":"2022-12-29T15:42:47.568158Z","shell.execute_reply":"2022-12-29T15:42:47.568193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.preprocessing import LabelEncoder\nX=np.array(extracted_features_df['features'].tolist())\ny=np.array(extracted_features_df[\"class\"].tolist())","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.570112Z","iopub.status.idle":"2022-12-29T15:42:47.570542Z","shell.execute_reply.started":"2022-12-29T15:42:47.570328Z","shell.execute_reply":"2022-12-29T15:42:47.570362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.572475Z","iopub.status.idle":"2022-12-29T15:42:47.573323Z","shell.execute_reply.started":"2022-12-29T15:42:47.573090Z","shell.execute_reply":"2022-12-29T15:42:47.573120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nLE=LabelEncoder()\ny=to_categorical(LE.fit_transform(y))","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.574905Z","iopub.status.idle":"2022-12-29T15:42:47.575730Z","shell.execute_reply.started":"2022-12-29T15:42:47.575491Z","shell.execute_reply":"2022-12-29T15:42:47.575522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.577477Z","iopub.status.idle":"2022-12-29T15:42:47.577905Z","shell.execute_reply.started":"2022-12-29T15:42:47.577704Z","shell.execute_reply":"2022-12-29T15:42:47.577724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape Of X_train:\",X_train.shape)\nprint(\"Shape Of X_test:\",X_test.shape)\nprint(\"Shape Of y_train:\",y_train.shape)\nprint(\"Shape Of y_test:\",y_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.579531Z","iopub.status.idle":"2022-12-29T15:42:47.579943Z","shell.execute_reply.started":"2022-12-29T15:42:47.579749Z","shell.execute_reply":"2022-12-29T15:42:47.579768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting labels\nnum_labels=y.shape[1]","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.581229Z","iopub.status.idle":"2022-12-29T15:42:47.581680Z","shell.execute_reply.started":"2022-12-29T15:42:47.581478Z","shell.execute_reply":"2022-12-29T15:42:47.581497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6\"></a> \n# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Model</center></h1> ","metadata":{}},{"cell_type":"code","source":"# Creating Our Model\n\nmodel=Sequential()\nmodel.add(Dense(100,input_shape=(40,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(200))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(200))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(100))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(num_labels))\nmodel.add(Activation('softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.583750Z","iopub.status.idle":"2022-12-29T15:42:47.584657Z","shell.execute_reply.started":"2022-12-29T15:42:47.584436Z","shell.execute_reply":"2022-12-29T15:42:47.584459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.585934Z","iopub.status.idle":"2022-12-29T15:42:47.587024Z","shell.execute_reply.started":"2022-12-29T15:42:47.586811Z","shell.execute_reply":"2022-12-29T15:42:47.586834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.588064Z","iopub.status.idle":"2022-12-29T15:42:47.589133Z","shell.execute_reply.started":"2022-12-29T15:42:47.588918Z","shell.execute_reply":"2022-12-29T15:42:47.588939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\n# tf.keras.callbacks.ModelCheckpoint\nfrom datetime import datetime\n\nnum_epochs=100\nnum_batch_size=32\n\ncheckpointer=ModelCheckpoint(filepath='saved_models/audio_classification.hdf5',verbose=1,save_best_only=True)\nstart=datetime.now()\nhistory = model.fit(X_train,y_train,batch_size=num_batch_size,epochs=num_epochs,validation_data=(X_test,y_test),callbacks=checkpointer)\n\nduration=datetime.now()-start\nprint(\"Training Completed in time: \",duration)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.590260Z","iopub.status.idle":"2022-12-29T15:42:47.591269Z","shell.execute_reply.started":"2022-12-29T15:42:47.591035Z","shell.execute_reply":"2022-12-29T15:42:47.591066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_accuracy_loss(history):\n    \"\"\"\n        Plot the accuracy and the loss during the training of the nn.\n    \"\"\"\n    fig = plt.figure(figsize=(10,5))\n\n    # Plot accuracy\n    plt.subplot(221)\n    plt.plot(history.history['accuracy'],'bo--', label = \"accuracy\")\n    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_accuracy\")\n    plt.title(\"train_accuracy vs val_accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epochs\")\n    plt.legend()\n\n    # Plot loss function\n    plt.subplot(222)\n    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n    plt.title(\"train_loss vs val_loss\")\n    plt.ylabel(\"loss\")\n    plt.xlabel(\"epochs\")\n\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.592649Z","iopub.status.idle":"2022-12-29T15:42:47.593547Z","shell.execute_reply.started":"2022-12-29T15:42:47.593284Z","shell.execute_reply":"2022-12-29T15:42:47.593305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracy_loss(history)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.595353Z","iopub.status.idle":"2022-12-29T15:42:47.595799Z","shell.execute_reply.started":"2022-12-29T15:42:47.595593Z","shell.execute_reply":"2022-12-29T15:42:47.595614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_accuracy=model.evaluate(X_test,y_test,verbose=0)\nprint(test_accuracy[1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"7\"></a> \n# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Testing our model</center></h1> ","metadata":{}},{"cell_type":"code","source":"# Testing an audio from test set\n\nfilename=\"/kaggle/input/musical-instruments-sound-dataset/Test_submission/Test_submission/Sad-Violin-Slow-K-www.fesliyanstudios.com.wav\"\naudio,sample_rate=librosa.load(filename,res_type='kaiser_fast')\nmfccs_features=librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\nmfccs_scaled_features =np.mean(mfccs_features.T,axis=0)\n\nprint(mfccs_scaled_features)\nmfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\nprint(mfccs_scaled_features)\n\npredicted_label = np.argmax(model.predict(mfccs_scaled_features), axis=-1)\nprint(predicted_label)\n\nprediction_class=LE.inverse_transform(predicted_label)\nprediction_class","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.597251Z","iopub.status.idle":"2022-12-29T15:42:47.597711Z","shell.execute_reply.started":"2022-12-29T15:42:47.597507Z","shell.execute_reply":"2022-12-29T15:42:47.597527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's play that sound\n\nimport IPython.display as ipd \nipd.Audio(filename)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T15:42:47.599188Z","iopub.status.idle":"2022-12-29T15:42:47.599625Z","shell.execute_reply.started":"2022-12-29T15:42:47.599417Z","shell.execute_reply":"2022-12-29T15:42:47.599437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"8\"></a> \n# <h1 style='background:#3b3a30; border:2; border-radius: 10px;padding-top: 2%;; font-size:200%; font-weight: bold; color:#c1502e'><center>Thank You</center></h1> \n \n### **If You Liked This Kernel Then Make An Upvote üëç. See You All With Another Dataset Attached Kernel .**\n### **Feel Free To Have A Look On It's Dataset .** \n\n### **You might like my another kernel[üê¶GUIDE TO:Audio Processing & FE With Birds Soundsüê¶](https://www.kaggle.com/code/soumendraprasad/guide-to-audio-processing-fe-with-birds-sounds/edit/run/114418780)** \n### **& it's  [üê¶Sound Of 114 Species Of Birds Till 2022ü¶ú Dataset .](https://www.kaggle.com/datasets/soumendraprasad/sound-of-114-species-of-birds-till-2022)**\n\n<img src=\"https://media.tenor.com/0MqQbvj3peYAAAAC/thinking-for-watching.gif\" width= 700 height = 450 />\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}